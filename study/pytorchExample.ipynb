{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "def rmse(y, y_hat):\n",
    "    \"\"\"\n",
    "    Compute root mean squared error\n",
    "    @param y: 입력 값\n",
    "    @param y_hat: 평균 값\n",
    "    return이 tensor로 되는데 결국 vector로 리턴되는 걸 의미\n",
    "    \"\"\"\n",
    "    return torch.sqrt(torch.mean((y - y_hat).pow(2).sum()))\n",
    "\n",
    "def forward(x, e):\n",
    "    \"\"\"Forward pass for our function\"\"\"\n",
    "    return x.pow(e.repeat(x.size(0)))\n",
    "\n",
    "# Let's define some settings\n",
    "n = 100 # number of examples\n",
    "learning_rate = 5e-6\n",
    "\n",
    "loss_history = []\n",
    "exp_history = []\n",
    "\n",
    "# Model definition\n",
    "x = Variable(torch.rand(n) * 10, requires_grad=False)\n",
    "\n",
    "# Model parameter and it's true value\n",
    "exp = Variable(torch.FloatTensor([2.0]), requires_grad=False)\n",
    "exp_hat = Variable(torch.FloatTensor([4]), requires_grad=True)\n",
    "y = forward(x, exp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "[tensor(30186.3359)] [tensor([2.8787e-01, 1.3854e+01, 1.0970e+01, 7.7573e+00, 1.3582e+01, 1.7623e+02,\n",
      "        1.8641e+03, 3.0177e+03, 5.5693e+01, 6.8382e+01, 8.1911e+02, 1.4489e+02,\n",
      "        5.3776e+03, 2.0038e+03, 5.8769e+00, 2.5226e+02, 2.3613e+01, 3.6729e+03,\n",
      "        1.3743e+00, 3.5686e+02, 5.1749e+02, 5.7448e+03, 8.2217e+03, 6.8777e+03,\n",
      "        2.8511e-03, 4.0517e+02, 1.2790e+01, 2.0632e+00, 1.7518e+03, 2.4766e+03,\n",
      "        8.4890e+02, 3.7828e+02, 1.1577e-01, 1.2033e+00, 1.5235e+02, 4.7783e+02,\n",
      "        3.4694e+03, 2.0344e+03, 7.8117e+03, 9.3250e+02, 7.1835e-03, 6.3783e+03,\n",
      "        1.9723e+03, 7.2871e+03, 1.1010e-01, 1.1457e+03, 1.3689e+01, 5.6806e+03,\n",
      "        9.3639e+03, 5.7987e+03, 2.5678e+03, 1.4426e+03, 9.4371e+03, 2.0421e-02,\n",
      "        7.5155e-05, 2.4519e-01, 4.1345e+02, 6.8486e+03, 2.9926e-01, 4.2779e+03,\n",
      "        3.9999e+03, 2.8884e+02, 3.8848e+02, 2.3723e+02, 3.8925e+02, 9.1577e+00,\n",
      "        2.0971e+02, 2.0214e-02, 1.5069e+00, 8.2062e+01, 7.0551e+03, 6.1716e+00,\n",
      "        2.0731e+02, 6.8105e+02, 2.5428e+02, 3.5495e+01, 1.3898e+02, 4.8015e+03,\n",
      "        2.3640e+00, 2.0787e+03, 5.4657e+02, 2.4259e+03, 4.3193e+03, 6.5351e+00,\n",
      "        8.7090e+01, 4.5946e+02, 5.8974e+02, 3.0334e+03, 2.1839e-01, 7.8278e+02,\n",
      "        5.9730e+02, 5.0537e+01, 6.0305e+00, 4.5694e+03, 2.0451e+03, 5.3939e+03,\n",
      "        2.1840e+03, 3.6946e-04, 5.8487e+03, 6.8096e+02])]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'back11ward'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(loss_history, exp_history)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Compute gradients\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mback11ward\u001B[49m()\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss = \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m loss\u001B[38;5;241m.\u001B[39mdata)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexp = \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m exp_hat\u001B[38;5;241m.\u001B[39mdata)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'back11ward'"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for i in range(0, 200):\n",
    "    print(\"Iteration %d\" % i)\n",
    "\n",
    "    # Compute current estimate\n",
    "    y_hat = forward(x, exp_hat)\n",
    "\n",
    "    # Calculate loss function\n",
    "    loss = rmse(y, y_hat)\n",
    "\n",
    "    # Do some recordings for plots\n",
    "    # PyTorch 버전 변경에 따라 Tensor object의 data는 아래와 같이 참조하는 것으로 변경\n",
    "    loss_history.append(loss.data)\n",
    "    exp_history.append(y_hat.data)\n",
    "    print(loss_history, exp_history)\n",
    "\n",
    "    # Compute gradients\n",
    "    loss.back11ward()\n",
    "\n",
    "    print(\"loss = %s\" % loss.data)\n",
    "    print(\"exp = %s\" % exp_hat.data)\n",
    "\n",
    "    # Update model parameters\n",
    "    exp_hat.data -= learning_rate * exp_hat.grad.data\n",
    "    exp_hat.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}